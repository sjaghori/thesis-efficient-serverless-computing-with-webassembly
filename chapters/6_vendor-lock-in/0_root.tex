\chapter{Vendor lock-in}
\label{chap:vendor-lock-in}

Cloud computing's vendor lock-in issue arises when customers become reliant (i.e., locked-in) on a specific cloud provider's technology implementation. This makes it challenging and costly to switch to another vendor due to legal constraints, technical incompatibilities, or significant expenses in the future. The issue of vendor lock-in in \gls{cloud computing} has been identified as a major challenge because transferring applications and data to other providers is often an expensive and time-consuming process, making portability and interoperability essential considerations \cite{guest_2013_oracle}.

There are two primary factors contributing to the difficulty of achieving interoperability, portability, compliance, trust, and security in cloud computing. The first is the absence of universally adopted standards, APIs, or interfaces that can leverage the ever-changing range of cloud services. The second is the lack of standardized practices for deployment, maintenance, and configuration \cite{oparamartins_2014_critical}, which creates challenges for ensuring consistency and compatibility across cloud environments. 

\section{Key Motivations for shifting to a new Cloud Provider}
There are various reasons why a customer may contemplate changing their service provider:

\begin{enumerate}
    \item Inconsistent or unreliable service quality
    \item Escalating costs associated with function execution, prompting a search for a more cost-effective alternative.
    \item Runtime issues or limitations encountered with the current provider.
    \item The need to integrate a function with a new back-end service that is only offered by a different provider.
    \item Strategic or support considerations within the organization that may necessitate a switch to a different Cloud provider.
\end{enumerate}

\subsection{Service interoperability}
\label{subsec:service-interoperability}

The interoperability between different vendors is a notable factor in the decision to switch providers. It is an active decision of a cloud provider to make their services interoperable with other providers. Due to lack of standardization, we can already see smaller cloud providers offering services that are compatible with the larger cloud providers. For example, Cloudflare's R2 service is compatible with AWS S3 \cite{cloudflareinc_cloudflare}. This allows customers to use Cloudflare's R2 service as a drop-in replacement for AWS S3, which is a significant advantage for customers who want to avoid vendor lock-in. 

Another alternative is the collaboration between cloud providers. An excellent example of such a partnership is WinterCG, which is described as "a community group to provide a space for JavaScript runtimes to collaborate on API interoperability \cite{webinteroperableruntimescommunitygroup_wintercg}". With this approach, cloud providers don't have to reinvent existing APIs and can focus on developing new features. On the other hand, this approach will make it easier for the developers to use the same codebase for different cloud providers.

\subsection{Which parts need to be considered when migrating to a different provider?}
To evaluate the feasibility of switching \Gls{FaaS} providers, it is necessary to examine the modifications needed for the function codebase as well as the adjustments required for the execution configuration, deployment, and triggers.

\subsubsection{Differences in handler function}
Each \gls{cloud computing} service provider has its own unique function signature that must be adhered to for the code to be executed on their respective cloud platforms. These signatures can vary slightly between different providers. The subsequent Javascript code examples illustrate how input can be read from the event and responses can be sent back for each cloud provider. These examples assume that the function is triggered through an HTTP POST request and with a JSON body conaining "myName" property. \\
The first example is an AWS Lambda function, the body is within the event object, the function resolves the request by returning an object that contains a "statusCode" property along with a body.

\begin{lstlisting}[frame=lines, style=ES6, caption={Basic AWS Lambda handler function}, showstringspaces=false, captionpos=b,]
export const handler = async(event, context) => {
  const input = JSON.parse(event.body);
  return {
      statusCode: 200,
      body: JSON.stringify({
          message: `Hello ${input.myName}`,
      })
  };
};
\end{lstlisting}
The next \gls{serverless} function is running on Google Cloud, the difference is not only in the function signature, but also the fact that the function imports the framework.

\begin{lstlisting}[frame=lines, style=ES6, caption={Basic Gen. 2 Google Cloud handler function}, showstringspaces=false, captionpos=b,]
const functions = require("@google-cloud/functions-framework");

functions.http("/", (req, res) => {
  res.status(200).send({
       message: `Hello ${req.body.myName}`
    });
});
\end{lstlisting}

Cloudflare Workers utilize \gls{V8} engine and thus they offer only JavaScript and TypeScript at the moment. The following example shows the handler function for a Cloudflare Worker. The fetch function comes with three parameters: "request", "env" and "ctx". The "request" parameter contains the HTTP request object, the "env" parameter contains the bindings assigned to the Worker and the "ctx" parameter contains commands like \texttt{ctx.waitUntil} or \texttt{ctx.passThroughOnException} to control the Worker's behavior. 

\begin{lstlisting}[frame=lines, style=ES6, caption={Basic Cloudflare Workers hanlder function}, showstringspaces=false, captionpos=b,]
export default {
  async fetch(request, env, ctx) {
      const input = JSON.parse(await request.text());
      return new Response(JSON.stringify({
          message: `Hello, ${input.myName}`,
      }), {
          status: 200,
          headers: {
              "content-type": "application/json",
          },
      });
  },
};
\end{lstlisting}

Lastly, the following example shows a basic Fastly Compute@Edge \cite{fastlyinc_serverless} function. Fastly functions are working with WebAssembly and Wasmtime runtime. The function explicitly adds an event listener to the "fetch" event. The "fetch" event is triggered when a request is made to the function. The function then parses the request body and returns a response with a status code of 200 and a JSON body containing a "message" property. As shown in the example below, the fetch handler does only have one parameter, the "event" parameter. The "event" parameter contains the request object. 

\begin{lstlisting}[frame=lines, style=ES6, caption={Basic Fastly Compute@Edge handler function}, showstringspaces=false, captionpos=b,]
addEventListener("fetch", (event) => event.respondWith(handleRequest(event)));

async function handleRequest(event) {
  const request = event.request;
  const input = JSON.parse(await request.text());
  return new Response(JSON.stringify({
    message: `Hello, ${input.myName}`,
  }), { 
    status: 200,
    headers: {
      "content-type": "application/json",
    },
  });
}
\end{lstlisting}

\section{Design principles}
\subsection{Facade pattern}
The \gls{facade} pattern can be used as a mitigation strategy to avoid or reduce \gls{serverless} vendor lock-in. By creating a facade layer between the serverless function and the vendor-specific implementation, it is possible to decouple the function from the vendor's specific implementation details.
The facade layer provides a simplified interface that abstracts the underlying vendor implementation, allowing developers to write code that is agnostic to the specific \gls{serverless} vendor. If the vendor needs to be changed, the facade layer can be modified to adapt to the new vendor-specific implementation without affecting the business logic or the interface of the serverless function. This way, the codebase remains modular, and changing vendors becomes a relatively straightforward task.

\subsection{Adapter pattern}

\subsubsection{SvelteKit}

SvelteKit is a modern web framework that effectively demonstrates the use of the Adapter pattern for deployment. Before deploying a SvelteKit application, it must be adapted to the specific deployment target by selecting an appropriate adapter in the configuration. This allows the application to be bundled with the platform-specific configuration \cite{sveltecommunity_2023_adapter}. 
The code snippet below illustrates the adapter configuration of a SvelteKit application, which enables the framework to be adapted to various cloud providers and allows the community to create new adapters. In this case, the deployment target is a Cloudflare Workers \gls{serverless} function.

\begin{lstlisting}[frame=lines, style=ES6, caption={svelte.config.js SvelteKit adapter configuration}, showstringspaces=false, captionpos=b,]
import adapter from '@sveltejs/adapter-cloudflare-workers';
 
/** @type {import('@sveltejs/kit').Config} */
const config = {
  kit: {
    adapter: adapter({
      // adapter options go here
    })
  }
};
 
export default config;
\end{lstlisting}

\subsubsection{Hono Web Framework}

Hono \cite{honocommunity_2023_hono} is a fast web framework which is also following the adapter pattern to allow developers to deploy their applications to various cloud providers without the need to change the business logic. The listing below shows a simple Hono endpoint which would look and work the same for Cloudflare Workers, Fastly Compute@Edge, Deno, Bun, Vercel, Lagon, AWS Lambda, and Node.js according to Hono js documentation \cite{honocommunity_2023_hono}. The only difference is in the adapter configuration and depending on the platform also the export line. 

\begin{lstlisting}[frame=lines, style=ES6, caption={Hono Handler function}, showstringspaces=false, captionpos=b,]
import { Hono } from 'hono'
const app = new Hono()

app.get('/', (c) => c.text('Hono!'))

export default app
\end{lstlisting}

%\section{The role of Wasm Portability}
